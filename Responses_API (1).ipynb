{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86832346-9e59-4811-83ff-04e2e007e515",
   "metadata": {},
   "source": [
    "# OpenAI Responses API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea36b9-4484-4e95-a023-41e475f1af58",
   "metadata": {},
   "source": [
    "## What is the OpenAI Responses API?\n",
    "\n",
    "The Responses API is a new API released in March 2025. It is a combination of the traditional \n",
    "Chat Completions API and the Assistants API, providing support for:\n",
    "\n",
    "- **Traditional Chat Completions:** Facilitates seamless conversational AI experiences.\n",
    "- **Web Search:** Enables real-time information retrieval from the internet.\n",
    "- **File Search:** Allows searching within files for relevant data.\n",
    "\n",
    "Accordingly, the Assistants API will be retired in 2026. \n",
    "\n",
    "> **For new users, OpenAI recommends using the Responses API instead of the Chat Completions API to leverage its expanded capabilities.**\n",
    "\n",
    "For a comprehensive comparison between the Responses API and the Chat Completions API, refer to the official OpenAI documentation: \n",
    "[Responses vs. Chat Completions](https://platform.openai.com/docs/guides/responses-vs-chat-completions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ae0b6-d8f5-4547-be96-bafdf768853c",
   "metadata": {},
   "source": [
    "## Summary of This Notebook\n",
    "This notebook provides a hands-on guide for using the **OpenAI Responses API** to analyze tweets. \n",
    "It covers essential techniques such as:\n",
    "\n",
    "- **Creating a vector store** and uploading tweets for semantic search.\n",
    "- **Using file search** to analyze private datasets.\n",
    "- **Performing a web search** to retrieve the latest public information.\n",
    "- **Utilizing stateful responses** to maintain conversation context.\n",
    "- **Combining file and web search** to enhance retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "By the end of this notebook, users will be able to integrate OpenAI's Responses API for efficient data retrieval and analysis of structured and unstructured data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe454d-ac76-413a-b17c-f79c4873e9df",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "To use the OpenAI Responses API, we need to install the following libraries:\n",
    "\n",
    "- **`openai`**: Provides access to OpenAI's APIs, including the Responses API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6346923a-a409-4621-a6fc-d0f72dccde48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9706b93-af03-4f7a-89bd-6649b11ba83c",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4f25ea-3dc7-4955-8589-0527ce749a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d0310-abab-49d2-9d7e-69c92112efd5",
   "metadata": {},
   "source": [
    "## Retrieve Secrets from AWS Secrets Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c8e717-0cbb-4125-8a3e-9ea5f1c92180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bbd9ff-e0bc-4ec0-9fbc-b2f931defe4e",
   "metadata": {},
   "source": [
    "## Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec97cf0-736c-439e-81e4-0d22a7b527bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef03684-10fa-433c-a9ff-5f322fd215c3",
   "metadata": {},
   "source": [
    "## File Search API\n",
    "\n",
    "### Introduction to File Search\n",
    "File search API enables efficient retrieval of relevant information \n",
    "from uploaded files by leveraging vector-based indexing. This feature is particularly useful \n",
    "for searching large datasets, extracting insights, and improving retrieval-augmented generation (RAG) applications.\n",
    "\n",
    "Unlike traditional keyword-based searches, the Responses API uses embeddings \n",
    "to identify semantically relevant content, making it ideal for analyzing structured \n",
    "and unstructured text data (OpenAI, 2025).\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[File Search in Responses API](https://platform.openai.com/docs/guides/tools-file-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12034ce9-04cc-4f03-8573-9328f05c3735",
   "metadata": {},
   "source": [
    "### Create a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2e24f19-be80-429e-8a9a-ece1da9a4ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_691264a2a1308191be1b1dfc13ecad44\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name=\"my_vector_store\"\n",
    ")\n",
    "vector_store_id = vector_store.id\n",
    "print(vector_store_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80e5ee-4317-4317-8e46-493c3f5d2e95",
   "metadata": {},
   "source": [
    "### Upload Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596ecef7-0b1a-4cbe-8e47-f7e13d6d6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-WA7damSVacnRiWPjVRKMvW\n"
     ]
    }
   ],
   "source": [
    "with open('tweet_text.json', 'rb') as f:\n",
    "    file = client.files.create(\n",
    "        file=f,            # file-like object\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "file_id = file.id\n",
    "print(file_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4c9ed-7b16-4178-914e-a4436b6d2971",
   "metadata": {},
   "source": [
    "### Attach File to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15874314-ed04-4315-85cc-e9ce4eee9d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-WA7damSVacnRiWPjVRKMvW\n"
     ]
    }
   ],
   "source": [
    "attach_status =client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store_id,\n",
    "    file_id=file_id\n",
    "            )\n",
    "\n",
    "print(attach_status.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091a9cf3-a802-41a1-9707-e04ee1bdfd8f",
   "metadata": {},
   "source": [
    "### Query the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf3753c0-b763-403d-be6a-368d80f6714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"the latest development in generativeAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c757b4d8-d603-4b01-a610-978b9cfa5010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They have been VERY clear that Chatgpt, these AI videos‚Ä¶\"\n",
      "  }\n",
      "},\n",
      "{\n",
      "  \"_id\": {\n",
      "    \"$oid\": \"68e56b1f1\n",
      " Relevant score: 0.6010846063542131\n",
      "Learning Plans. Use coupon code ùêíùêèùêãùüëùüé at checkout.üéØ\\n\\nJoin Now üëâ https://t.co/LS2JuCrVmz\\n\\n#AI #Ce\n",
      " Relevant score: 0.5987078953443187\n",
      "Create stunning, cinematic videos from a prompt‚Äînow with audio, physics, and cameos. One prompt = en\n",
      " Relevant score: 0.5911156596667607\n",
      "They have been VERY clear that Chatgpt, these AI videos‚Ä¶\"\n",
      "  }\n",
      "},\n",
      "{\n",
      "  \"_id\": {\n",
      "    \"$oid\": \"68e56b1d1\n",
      " Relevant score: 0.5622353955032359\n",
      "ü§§ AI is making cinematic food commercials in minutes. The sizzling patty, the dripping cheese... no \n",
      " Relevant score: 0.551242779477055\n"
     ]
    }
   ],
   "source": [
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_id,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "for result in search_results.data[:5]:\n",
    "    print(result.content[0].text[:100] + '\\n Relevant score: ' + str(result.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d89abc-a919-4563-9f06-8dfc9410a4ab",
   "metadata": {},
   "source": [
    "## OpenAI Response API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1ecaa-6836-41d5-847e-853b62bcdd0b",
   "metadata": {},
   "source": [
    "### Simple Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e96e622-9b8c-47d5-9a4a-3c3e6315b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_response = client.responses.create(\n",
    "  model=\"gpt-4o\",\n",
    "  input=[\n",
    "      {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": query\n",
    "      }\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1c7e17d-a20d-40e2-b1bc-ee30f9199627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of 2023, there have been several exciting developments in generative AI:\n",
       "\n",
       "1. **Multimodal Models**: Advanced AI systems that can process and generate text, images, audio, and video, such as OpenAI's GPT-4 and its successors, offer enhanced capabilities by integrating different forms of media.\n",
       "\n",
       "2. **Improved Text Generation**: Models capable of creating more coherent and contextually relevant content with better understanding of nuances in language, leading to applications in content creation, customer support, and creative writing.\n",
       "\n",
       "3. **Image and Art Generation**: Tools like DALL-E and Midjourney enable the creation of highly detailed and imaginative artwork, supporting artists and designers in various creative fields.\n",
       "\n",
       "4. **Ethical AI Advances**: Greater emphasis on responsible AI development with frameworks to address biases, ensure fairness, and improve transparency in generative models.\n",
       "\n",
       "5. **Real-time AI Applications**: Breakthroughs in reducing latency allow for real-time applications of generative AI in gaming, virtual reality, and personalized content generation.\n",
       "\n",
       "6. **Domain-specific Models**: Tailored generative models for specific industries, such as pharmaceuticals for drug discovery or finance for market analysis, optimizing outputs for specialized needs.\n",
       "\n",
       "7. **Collaboration with Humans**: Tools designed to assist rather than replace human creators, enhancing creativity through AI-driven suggestions and collaborative workflows.\n",
       "\n",
       "These developments underscore the rapid evolution of generative AI, highlighting its expanding role across numerous sectors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(simple_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b468693-2250-4b09-994e-2eb52b1d5741",
   "metadata": {},
   "source": [
    "### File Search Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4061d68-56f6-4dfc-974c-b2446ad79ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_search_response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature = 0,\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d448b96-b931-4af8-bd71-1f8facd44ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The latest developments in generative AI include several exciting advancements:\n",
       "\n",
       "1. **OpenAI's Sora2**: This tool allows users to create cinematic videos from a prompt, now with added features like audio, physics, and cameos, offering endless creativity for creators.\n",
       "\n",
       "2. **GPT-5 and DALL¬∑E 4**: These models are being used to create unique multimedia experiences, such as combining quantum fractals with music generation.\n",
       "\n",
       "3. **Generative AI in Business**: Companies like Atos are using generative AI for supply chain disruption analysis, integrating it with platforms like SAP and AWS to assess risks and boost resilience.\n",
       "\n",
       "4. **AI in Creative Industries**: Generative AI is transforming creative fields by enabling the production of content like cinematic food commercials without traditional sets or crews.\n",
       "\n",
       "5. **Enterprise Applications**: IBM's Watsonx is bringing generative AI to enterprises, allowing teams to build custom large language models to enhance customer engagement and streamline processes.\n",
       "\n",
       "These developments highlight the diverse applications and transformative potential of generative AI across various sectors."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(file_search_response.output_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd7ddc-64d0-49dc-a0f7-c24a4a1b8c31",
   "metadata": {},
   "source": [
    "## Web Search API\n",
    "\n",
    "### Introduction to Web Search\n",
    "The OpenAI Web Search tool allows models to retrieve real-time information from the internet. \n",
    "This capability is particularly useful for obtaining up-to-date data, fact-checking, and expanding knowledge \n",
    "without relying solely on pre-trained information. \n",
    "\n",
    "By leveraging OpenAI's web search functionality, the Responses API can fetch external data \n",
    "and provide accurate, relevant results in real time (OpenAI, 2025). \n",
    "This feature enhances applications that require the latest insights, such as news aggregation, research, \n",
    "or dynamic content generation.\n",
    "\n",
    "For more details, visit the official OpenAI documentation: \n",
    "[Web Search in Responses API](https://platform.openai.com/docs/guides/tools-web-search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2bc7e-9a56-4695-8148-915d875ad716",
   "metadata": {},
   "source": [
    "### Perform Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "455aae40-d752-4e05-b8b6-da213e9b1f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1f5d2c4-f2fb-4261-bc7e-f5b5924f9959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs an in‚Äëdepth, structured update on the **latest developments in generative AI** as of **November 10, 2025**, encompassing both industry milestones and academic innovations.\n",
       "\n",
       "---\n",
       "\n",
       "##  1. Cutting‚ÄëEdge Model Releases & Deployments\n",
       "\n",
       "- **OpenAI** released **GPT‚Äë5** on **August 7, 2025**‚Äîa multimodal foundational model that powers ChatGPT and Microsoft‚Äôs Copilot. It delivers improved performance, safety enhancements, and is widely accessible via API and free-tier usage limits.([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai))\n",
       "\n",
       "- Also noteworthy, **OpenAI unveiled ‚ÄúAardvark‚Äù**‚Äîa **GPT‚Äë5‚Äìpowered autonomous security researcher**. Currently in private beta, Aardvark identifies software vulnerabilities with ~92% recall and has already contributed to 10 CVE‚Äëtracked disclosures.([aiwebbiz.com](https://aiwebbiz.com/blog/top-5-ai-news-of-the-week-november-2025/?utm_source=openai))\n",
       "\n",
       "- **Google DeepMind‚Äôs Gemini family** continues advancing. Notable within this is **‚ÄúNano Banana‚Äù** (Gemini 2.5 Flash Image), introduced in **August 2025**. This text-to-image editor went viral for generating photorealistic 3D-figurine-style images and supports features like multi-image fusion and SynthID watermarking.([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai))\n",
       "\n",
       "- A **Nano Banana 2** is now on the horizon, expected to launch within weeks. It promises faster generation, enhanced stylistic diversity, and deeper integration with the upcoming Gemini 3.0 series.([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  2. Major Product Integrations & Ecosystem Expansion\n",
       "\n",
       "- **OpenAI‚Äôs Sora**, a video-gen model, saw explosive adoption: ~470,000 Android downloads on its first day and ~360,000 on iOS. Its second iteration, **Sora‚ÄØ2**, was launched on **October 1, 2025**, bringing synchronized audio, cinematic styles, and enhanced consistency across clips.([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "- **Google Gemini AI** is deepening its utility:\n",
       "  - Introduced **Deep Research**‚Äîpowerful multimodal querying across Gmail, Drive, Chat, and standard search to generate contextual, personalized insights.([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "  - A **Gemini 3 Pro preview** appeared in **Vertex AI**, expected to arrive soon with a milestone 1-million-token context window for more complex tasks.([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  3. Industry Players Expanding AI Capabilities\n",
       "\n",
       "- **Qualcomm** unveiled two new AI inference accelerators‚Äî**AI200** and **AI250**‚Äîdesigned for data center deployments by 2026‚Äì2027. Features include high memory bandwidth, scalable design, and compatibility with PyTorch/ONNX, positioning Qualcomm as a competitive force against NVIDIA and AMD.([tomshardware.com](https://www.tomshardware.com/tech-industry/artificial-intelligence/qualcomm-unveils-ai200-and-ai250-ai-inference-accelerators-hexagon-takes-on-amd-and-nvidia-in-the-booming-data-center-realm?utm_source=openai))\n",
       "\n",
       "- **Google** launched the **TIME AI Agent**, developed with Scale AI. Released today (November 10, 2025), it‚Äôs a generative-AI-powered platform enabling interactive news consumption ‚Äî from summarization to audio reports and translations, while maintaining editorial integrity.([time.com](https://time.com/7332572/the-story-behind-the-time-ai-agent/?utm_source=openai))\n",
       "\n",
       "- **Google** also announced a **Generative AI Leader certification for veterans**, starting **November 13‚Äì14, 2025**, part of a broader push to retrain service members for tech careers using generative AI skills.([startuphub.ai](https://www.startuphub.ai/ai-news/ai-research/2025/google-accelerates-veteran-ai-training-initiatives/?utm_source=openai))\n",
       "\n",
       "- **BrainChip**, an Australian neuromorphic AI company, raised A$35 million (with an additional A$2 million planned) to accelerate its **Akida edge AI platform** and next-gen products.([sharecafe.com.au](https://www.sharecafe.com.au/2025/11/10/brainchip-announces-a35-million-placement-and-share-purchase-plan/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  4. Quantum-Enhanced Generative AI Research\n",
       "\n",
       "- A landmark study published in **September 2025** demonstrates **generative quantum advantage** using a 68‚Äëqubit superconducting processor. These quantum models can learn and generate classically intractable distributions, marking a breakthrough toward quantum-enhanced generative AI.([arxiv.org](https://arxiv.org/abs/2509.09033?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "##  5. Key Themes & Strategic Overview\n",
       "\n",
       "- **Multimodality continues to dominate**: Models like GPT‚Äë5, Gemini image variants, and Sora‚ÄØ2 integrate text, image, video, and audio in unified interfaces‚Äîpushing toward more immersive and versatile AI.([gartner.com](https://www.gartner.com/en/newsroom/press-releases/2024-09-09-gartner-predicts-40-percent-of-generative-ai-solutions-will-be-multimodal-by-2027?utm_source=openai))\n",
       "\n",
       "- **Agentic intelligence emerges**: Features like Aardvark (autonomous security detection), Gemini Deep Research, and Sora 2‚Äôs planning-oriented design reflect a shift from passive AI to systems that proactively operate within workflows.([aiwebbiz.com](https://aiwebbiz.com/blog/top-5-ai-news-of-the-week-november-2025/?utm_source=openai))\n",
       "\n",
       "- **Infrastructure and regulation focus**: Industry players are bolstering infrastructure (Qualcomm‚Äôs accelerators) and talent pipelines (Google‚Äôs veteran program). Meanwhile, deployment at scale continues with attention on governance and editorial integrity (TIME AI Agent).([startuphub.ai](https://www.startuphub.ai/ai-news/ai-research/2025/google-accelerates-veteran-ai-training-initiatives/?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "### Summary Snapshot\n",
       "\n",
       "| Category                     | Highlight                                                                   |\n",
       "|------------------------------|-----------------------------------------------------------------------------|\n",
       "| Model Releases               | GPT‚Äë5, Aardvark, Nano Banana, Nano Banana 2 (upcoming), Sora‚ÄØ2              |\n",
       "| Ecosystem Integrations       | Gemini Deep Research, Vertex AI glimpse of Gemini‚ÄØ3‚ÄØPro                    |\n",
       "| Infrastructure & Access      | Qualcomm AI200/250, TIME AI Agent, veteran certification, BrainChip funding |\n",
       "| Research Breakthroughs       | Quantum generative models with demonstrated advantage                      |\n",
       "\n",
       "---\n",
       "\n",
       "If you‚Äôd like to dive deeper into any specific development‚Äîbe it performance benchmarks, deployment timelines, or comparative analyses‚Äîjust let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(web_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85df607-d638-4d58-99a8-99a6cfe2d7e8",
   "metadata": {},
   "source": [
    "### Stateful Response\n",
    "\n",
    "The OpenAI Responses API includes a stateful feature that enables continuity in interactions. \n",
    "By using the `response_id`, a conversation can persist across multiple queries, \n",
    "allowing users to refine or expand upon previous searches. This is particularly useful for iterative research, \n",
    "dynamic content generation, and applications that require follow-up queries based on prior responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b3e83a4-3437-4e9f-9732-748a35ccd43f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs an in‚Äëdepth, structured update on the **latest developments in generative AI** as of **Novemb"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetched_response = client.responses.retrieve(response_id=web_search_response.id)\n",
    "display(Markdown(fetched_response.output_text[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ca4d4-b2f7-4cd2-94b6-a0d2aec179cb",
   "metadata": {},
   "source": [
    "### Continue Query with Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b348e31e-3aea-4656-b86e-b0f62ef9c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_query = 'find different news'\n",
    "\n",
    "continue_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= continue_query,\n",
    "    previous_response_id=web_search_response.id,\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3ecd050-c5e3-44ca-869b-657e90aca446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a **detailed, up-to-date**, and well-structured overview of the latest developments in **generative AI** as of **November 10, 2025**. These updates reflect news through early November and cover industry-leading model releases, product integrations, hardware, policy, and academic advances. Each statement is clearly cited for accuracy.\n",
       "\n",
       "---\n",
       "\n",
       "##  Generative AI: Key Breakthroughs and Product Launches\n",
       "\n",
       "### OpenAI and Agentic AI\n",
       "- **OpenAI unveiled ‚ÄúAardvark,‚Äù** a GPT-5-powered agentic security researcher in private beta on **October 30, 2025**. It autonomously discovers software vulnerabilities with about 92% recall and has contributed to multiple CVE disclosures ([aiwebbiz.com](https://aiwebbiz.com/blog/top-5-ai-news-of-the-week-november-2025/?utm_source=openai)).\n",
       "- **Sora video app** experienced explosive uptake, with approximately 470,000 downloads on Android and 360,000 on iOS on its first day (November 6) ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai)).\n",
       "\n",
       "### Google‚Äôs Expanding Ecosystem\n",
       "- **Gemini‚Äôs ‚ÄúDeep Research‚Äù** now empowers users to query Gmail, Drive, Chat, and standard search, generating high-context, customized results ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai)).\n",
       "- A **preview of Gemini 3 Pro** appeared on Vertex AI, expected to deliver a massive 1 million-token context window for advanced developer use ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai)).\n",
       "- **Veo 3.1**, the latest update to Google‚Äôs text-to-video model, enhances narrative control, enables extended clip generation via keyframe interpolation, and is available through paid preview via the Gemini API ([voxfor.com](https://www.voxfor.com/what-is-new-in-ai-the-latest-news-from-october-2025/?utm_source=openai)).\n",
       "- **Gemini Nano Banana 2** is slated for release soon, promising faster image generation and a broader stylistic range, integrated with the upcoming Gemini 3.0 series ([medium.com](https://medium.com/%40CherryZhouTech/ai-news-november-1-7-2025-10-ai-advances-you-cant-miss-this-week-e2e86d331bd0?utm_source=openai)).\n",
       "- In **October 2025**, Google rolled out numerous AI innovations including a verifiable quantum algorithm with 13,000√ó speed-up, **Gemini for Home**, **Gemini Enterprise** for secure workplace AI, **vibe coding** in AI Studio, Flow editing enhancements, AI-powered updates to Google Home and Android XR devices, and the launch of a learning platform, Google Skills ([blog.google](https://blog.google/technology/ai/google-ai-updates-october-2025/?utm_source=openai)).\n",
       "\n",
       "### Anthropic and Agentic Efficiency\n",
       "- **Claude 3.7 Sonnet**, launched earlier in 2025, offers a hybrid reasoning mode called ‚Äúextended thinking,‚Äù designed for tasks like coding, physics, and math. It notably costs less than OpenAI‚Äôs comparable models ([reuters.com](https://www.reuters.com/technology/artificial-intelligence/anthropic-launches-advanced-ai-hybrid-reasoning-model-2025-02-24/?utm_source=openai)).\n",
       "- Additionally, **Anthropic introduced Claude Haiku 4.5**, a lightweight but high-performing model delivering GPT-5-level reasoning and coding power at 4‚Äì5√ó speed and significantly lower cost. It supports a 200K token context window and agentic function execution, ideal for automation tasks ([voxfor.com](https://www.voxfor.com/what-is-new-in-ai-the-latest-news-from-october-2025/?utm_source=openai)).\n",
       "\n",
       "### Creative Tools and Multimedia AI\n",
       "- **Adobe MAX 2025** revealed the **Firefly Image Model 5**, enabling higher-quality image and video creation across Adobe Express, Firefly, Creative Cloud, and GenStudio. Integration with Google‚Äôs Nano Banana was also announced ([timesofindia.indiatimes.com](https://timesofindia.indiatimes.com/technology/tech-news/adobe-launches-ai-audio-video-and-photo-tools-across-express-firefly-and-creative-cloud-brings-firefly-image-model-5-googles-nano-banana-and-more/articleshow/124876149.cms?utm_source=openai)).\n",
       "- Earlier in the year, Adobe released **Firefly Image Model 4 and 4 Ultra**, offering enhanced speed, realism, customization, high-resolution capabilities, plus a new collaborative moodboarding tool, Firefly Boards, in public beta ([theverge.com](https://www.theverge.com/news/655230/adobe-ai-firefly-image-model-4-availability?utm_source=openai)).\n",
       "- **Runway Gen-4**, released March 31, 2025, is a text-to-video model that generates up to 10-second clips using transformer and diffusion architecture. While promising, it still shows limitations in character consistency and motion realism ([en.wikipedia.org](https://en.wikipedia.org/wiki/Gen-4_%28AI_image_and_video_model%29?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Hardware Advancements & Compute Power Race\n",
       "\n",
       "- **Qualcomm** introduced **AI200 and AI250** inference accelerators designed for data centers. AI200 is expected in 2026 with AI250 following in 2027. They offer features like micro-tile inferencing, high memory bandwidth, Gen AI model encryption, and compatibility with AI frameworks ([tomshardware.com](https://www.tomshardware.com/tech-industry/artificial-intelligence/qualcomm-unveils-ai200-and-ai250-ai-inference-accelerators-hexagon-takes-on-amd-and-nvidia-in-the-booming-data-center-realm?utm_source=openai)).\n",
       "- **NVIDIA**, at GTC 2025, launched next-gen chips: **Blackwell Ultra** (late 2025), **Vera Rubin** (late 2026), and **Rubin Ultra** (2027). The company also presented the Cosmos video model for training data generation, the Isaac GR00T N1 robotics model, the Halos autonomous safety system, and the Newton physics engine co-developed with DeepMind and Disney Research ([apnews.com](https://apnews.com/article/457e9260aa2a34c1bbcc07c98b7a0555?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Regulatory, Industry, and Business Integration\n",
       "\n",
       "- **Regulatory and educational moves**: NTT Data (Japan) announced plans to train its 200,000 employees in generative AI literacy ([ninjaai.com](https://www.ninjaai.com/top-ai-news-for-october-30-2025?utm_source=openai)).\n",
       "- **Legal confrontations**: Palantir filed suit against former employees for alleged AI trade secret theft ([ninjaai.com](https://www.ninjaai.com/top-ai-news-for-october-30-2025?utm_source=openai)).\n",
       "- **Geopolitical collaborations**: Google and NextEra are reviving an Iowa nuclear plant to power AI data centers ([ninjaai.com](https://www.ninjaai.com/top-ai-news-for-october-30-2025?utm_source=openai)).\n",
       "- **EU regulatory updates**: New transparency and audit rules for generative AI systems; Vietnam is drafting similar legislation ([ninjaai.com](https://www.ninjaai.com/top-ai-news-for-october-30-2025?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "##  Trends & Strategic Shifts\n",
       "\n",
       "- **Agentic AI is rising**: Models like Aardvark, DS STAR, Claude Haiku 4.5, and Gemini Enterprise demonstrate AI evolving from reactive tools to proactive agents ([agiyes.com](https://www.agiyes.com/ainews/ai-news-from-november-1-7-2025/?utm_source=openai)).\n",
       "- **Multimodal expansion continues**: Veo models, Nano Banana 2, Sora, Gemini‚Äôs multimodal integrations, and Firefly‚Äôs suite show strong push toward integrating text, image, video, and audio generation ([theverge.com](https://www.theverge.com/news/655230/adobe-ai-firefly-image-model-4-availability?utm_source=openai)).\n",
       "- **Hardware scaling intensifies**: Investments from Qualcomm and NVIDIA are gearing up to meet growing generative AI compute demands ([tomshardware.com](https://www.tomshardware.com/tech-industry/artificial-intelligence/qualcomm-unveils-ai200-and-ai250-ai-inference-accelerators-hexagon-takes-on-amd-and-nvidia-in-the-booming-data-center-realm?utm_source=openai)).\n",
       "- **AI regulation and ethics gaining ground**: Legal tensions and new compliance frameworks reflect growing concern over IP and transparency ([ninjaai.com](https://www.ninjaai.com/top-ai-news-for-october-30-2025?utm_source=openai)).\n",
       "\n",
       "---\n",
       "\n",
       "### Summary Table\n",
       "\n",
       "| Category                 | Highlights |\n",
       "|--------------------------|------------|\n",
       "| Agentic & Security AI    | Aardvark, Claude Haiku 4.5, DS STAR |\n",
       "| Video & Image Generation | Veo 3.1, Gemini Nano Banana 2, Sora, Firefly 5 |\n",
       "| Hardware & Infrastructure| Qualcomm AI200/250, NVIDIA Blackwell/Rubin |\n",
       "| Regulation & Integration | NTT Data training, legal cases, energy infrastructure, regulations |\n",
       "\n",
       "---\n",
       "\n",
       "If you'd like further exploration‚Äîsuch as breakdowns of model performance, enterprise deployment case studies, or policy comparisons‚Äîjust let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(continue_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132125be-48d9-4596-9dc5-bc12dca5fdbf",
   "metadata": {},
   "source": [
    "### Combining File Search and Web Search\n",
    "\n",
    "This is an example of using file search to analyze private data and web search to retrieve public or the latest data. \n",
    "The Responses API allows developers to integrate these tools to enhance retrieval-augmented generation (RAG) applications. \n",
    "By combining file search with web search, users can leverage structured internal knowledge while also retrieving real-time \n",
    "information from external sources, ensuring comprehensive and up-to-date responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6344e43c-8aa4-4693-aaf6-20f09f416364",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",  # or another supported model\n",
    "    input= query,\n",
    "    temperature = 0,\n",
    "    instructions=\"Retrieve the results from the file search first, and use the web search tool to expand the results with news resources\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a09ee0a6-3b50-43a3-a63b-3c765da85561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here‚Äôs a comprehensive and up-to-date overview of the **latest developments in generative AI** as of November 10, 2025. This analysis draws on recent news, academic findings, and industry releases to highlight key breakthroughs across models, multimodal capabilities, hardware, open-source access, and real-world applications.\n",
       "\n",
       "---\n",
       "\n",
       "## 1. Cutting-Edge Generative AI Models\n",
       "\n",
       "- **OpenAI GPT‚Äë5**  \n",
       "  Released on August 7, 2025, GPT‚Äë5 is a multimodal foundation model that integrates reasoning and non-reasoning capabilities under a unified interface. It is accessible via ChatGPT, Microsoft Copilot, and the OpenAI API, and represents the current state-of-the-art in performance benchmarks. ([en.wikipedia.org](https://en.wikipedia.org/wiki/GPT-5?utm_source=openai))\n",
       "\n",
       "- **OpenAI o4‚Äëmini**  \n",
       "  Launched on April 16, 2025, o4‚Äëmini is a lightweight, multimodal reasoning model available to all ChatGPT users. It supports both text and image inputs, including whiteboard sketch analysis, and includes a higher-accuracy ‚Äúo4‚Äëmini‚Äëhigh‚Äù variant for paid users. ([en.wikipedia.org](https://en.wikipedia.org/wiki/OpenAI_o4-mini?utm_source=openai))\n",
       "\n",
       "- **Anthropic Claude 3.7 Sonnet**  \n",
       "  Introduced in February 2025, this hybrid reasoning model offers an ‚Äúextended thinking mode‚Äù that enables self-reflection before responding, improving performance in math, physics, coding, and other complex tasks. It is available across all Claude plans, with the extended mode reserved for paid tiers. ([reuters.com](https://www.reuters.com/technology/artificial-intelligence/anthropic-launches-advanced-ai-hybrid-reasoning-model-2025-02-24/?utm_source=openai))\n",
       "\n",
       "- **OpenAI‚Äôs Open-Weight Models (gpt‚Äëoss‚Äë20b and gpt‚Äëoss‚Äë120b)**  \n",
       "  In August 2025, OpenAI released its first open-weight models since GPT‚Äë2. These models support chain-of-thought reasoning and can run locally‚Äîgpt‚Äëoss‚Äë20b on consumer hardware (e.g., Snapdragon PCs), and gpt‚Äëoss‚Äë120b on more powerful setups like NVIDIA RTX GPUs. ([windowscentral.com](https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/openai-launches-two-gpt-models-theyre-not-gpt-5-but-they-run-locally-on-snapdragon-pcs-and-nvidia-rtx-gpus?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "## 2. Multimodal and Creative AI Innovations\n",
       "\n",
       "- **Google DeepMind‚Äôs ‚ÄúNano Banana‚Äù (Gemini 2.5 Flash Image)**  \n",
       "  Released on August 26, 2025, this image generation and editing model went viral for its photorealistic ‚Äú3D figurine‚Äù outputs. It supports features like subject consistency, multi-image fusion, and SynthID watermarking, and has driven over 10 million new users to the Gemini app. ([en.wikipedia.org](https://en.wikipedia.org/wiki/Nano_Banana?utm_source=openai))\n",
       "\n",
       "- **Generative AI for Multimedia**  \n",
       "  In 2025, models have increasingly unified text, image, audio, and video generation. Notable examples include:\n",
       "  - **Google‚Äôs Veo 3**: A text-to-video model with integrated audio generation. ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai))\n",
       "  - **OpenAI‚Äôs Sora**: A video generation tool integrated into ChatGPT for Plus users. ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai))\n",
       "  - **Midjourney V7**: Adds 3D model generation and video capabilities. ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai))\n",
       "  - **Runway Gen‚Äë4**: Introduces ‚ÄúCharacter Lock‚Äù to maintain character consistency across video scenes. ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai))\n",
       "  - **Stability AI‚Äôs Stable Audio 2.0**: Enhances AI music generation with better structure and emotional control. ([aiinsight.blog](https://aiinsight.blog/generative-ai-advancements-in-2025?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "## 3. Hardware and Infrastructure Advances\n",
       "\n",
       "- **NVIDIA Rubin and Blackwell Chips**  \n",
       "  At GTC 2025, NVIDIA unveiled its next-gen AI chips: Blackwell Ultra (launching late 2025) and Rubin (late 2026), with Rubin Ultra following in 2027. These chips are designed to support generative and agentic AI, robotics, and physical AI applications. ([apnews.com](https://apnews.com/article/457e9260aa2a34c1bbcc07c98b7a0555?utm_source=openai))\n",
       "\n",
       "- **Qualcomm AI200 and AI250 Accelerators**  \n",
       "  Announced in late October 2025, these upcoming AI inference accelerators target data center workloads. The AI200 (2026) and AI250 (2027) offer high memory capacity, advanced NPUs, and features like micro-tile inferencing and model encryption. ([tomshardware.com](https://www.tomshardware.com/tech-industry/artificial-intelligence/qualcomm-unveils-ai200-and-ai250-ai-inference-accelerators-hexagon-takes-on-amd-and-nvidia-in-the-booming-data-center-realm?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "## 4. Open-Source and Democratization of AI\n",
       "\n",
       "- **OpenAI‚Äôs Open-Weight Models**  \n",
       "  The release of gpt‚Äëoss‚Äë20b and gpt‚Äëoss‚Äë120b marks a significant shift toward openness, enabling local deployment and broader access to powerful AI capabilities. ([windowscentral.com](https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/openai-launches-two-gpt-models-theyre-not-gpt-5-but-they-run-locally-on-snapdragon-pcs-and-nvidia-rtx-gpus?utm_source=openai))\n",
       "\n",
       "- **Hugging Face SmolLM3 and Liquid AI LFM2**  \n",
       "  - **SmolLM3**: A 3B-parameter open-source LLM with a 128K token context window, outperforming similar-sized models. ([linkedin.com](https://www.linkedin.com/pulse/top-generative-ai-updates-week-july-2-2025-kalyan-ks-oorrc?utm_source=openai))  \n",
       "  - **LFM2**: A family of small foundation models (350M‚Äì1.2B parameters) optimized for on-device deployment, offering faster training and inference. ([linkedin.com](https://www.linkedin.com/pulse/top-generative-ai-updates-week-july-2-2025-kalyan-ks-oorrc?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "## 5. Real-World Applications and Research\n",
       "\n",
       "- **Protein Design with Diffusion Models**  \n",
       "  A 2025 study highlights the success of diffusion-based generative models like RFDiffusion in de novo protein design, achieving higher success rates and lower experimental costs compared to traditional methods. ([arxiv.org](https://arxiv.org/abs/2504.16479?utm_source=openai))\n",
       "\n",
       "- **Semantic Frameworks for Multimedia AI**  \n",
       "  A recent academic paper proposes a semantic information-theoretic framework for generative AI in multimedia communication, introducing concepts like semantic entropy and mutual information to improve semantic fidelity. ([arxiv.org](https://arxiv.org/abs/2508.17163?utm_source=openai))\n",
       "\n",
       "---\n",
       "\n",
       "## Summary Table\n",
       "\n",
       "| Area                     | Key Developments                                                                 |\n",
       "|--------------------------|----------------------------------------------------------------------------------|\n",
       "| **Models**               | GPT‚Äë5, o4‚Äëmini, Claude 3.7 Sonnet, open-weight models (gpt‚Äëoss)                  |\n",
       "| **Multimodal AI**        | Nano Banana, Veo 3, Sora, Midjourney V7, Runway Gen‚Äë4, Stable Audio 2.0          |\n",
       "| **Hardware**             | NVIDIA Blackwell/Rubin chips, Qualcomm AI200/AI250 accelerators                  |\n",
       "| **Open-Source Access**   | gpt‚Äëoss models, SmolLM3, LFM2                                                    |\n",
       "| **Applications & Research** | Protein design, semantic multimedia frameworks                                 |\n",
       "\n",
       "---\n",
       "\n",
       "### Final Thoughts\n",
       "\n",
       "Generative AI in 2025 is characterized by:\n",
       "\n",
       "- **Multimodal integration**: Models now seamlessly handle text, image, audio, and video.\n",
       "- **Reasoning and autonomy**: Features like ‚Äúthinking modes‚Äù and agentic capabilities are becoming standard.\n",
       "- **Hardware acceleration**: New chips and accelerators are being developed to meet the demands of generative workloads.\n",
       "- **Democratization**: Open-weight models and efficient architectures are making powerful AI more accessible.\n",
       "- **Real-world impact**: From protein design to semantic communication, generative AI is driving innovation across domains.\n",
       "\n",
       "Let me know if you'd like a deeper dive into any specific model, application, or technology!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(combined_search_response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac39c8-d345-4faf-a98f-2301b96e80a2",
   "metadata": {},
   "source": [
    "# üß© Try It Yourself: Two-Step RAG (Private Data + Combined Search)\n",
    "\n",
    "## Step 1 ‚Äî Upload & Create Vector Store\n",
    "1. Upload a short text file (e.g., `my_notes.txt`) to your notebook instance.  \n",
    "2. Create a **vector store** and **ingest** your uploaded file.  \n",
    "3. Run a simple test query to verify retrieval:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9eedf50-48f8-4092-bb20-c150f3848671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-HpqBFSgvEVyZpbCHSmQt7m\n",
      "vs_69126bfcf6f08191b347cb2896693a4a\n",
      "file-HpqBFSgvEVyZpbCHSmQt7m\n"
     ]
    }
   ],
   "source": [
    "with open('pollinator.txt', 'rb') as f:\n",
    "    file = client.files.create(\n",
    "        file=f,\n",
    "        purpose=\"assistants\"\n",
    "    )\n",
    "\n",
    "file_id = file.id\n",
    "print(file_id)\n",
    "\n",
    "vector_store = client.vector_stores.create(\n",
    "    name=\"my_vector_store\"\n",
    ")\n",
    "vector_store_id = vector_store.id\n",
    "print(vector_store_id)\n",
    "\n",
    "attach_status =client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store_id,\n",
    "    file_id=file_id\n",
    "            )\n",
    "\n",
    "print(attach_status.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32ea898b-90e9-48a6-aece-e68ef0408a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on contributions to the literature, the transition will continue \n",
      "to  advocate  for  the  role\n",
      " Relevant score: 0.7723596846774967\n",
      "5. Conclusion\n",
      "\n",
      "A  widespread  decline  in  pollinators  will  render  our  planet  less \n",
      "vibrant and\n",
      " Relevant score: 0.7571225995489589\n",
      "Three  separate  studies  examined  the  effects  of  neonicotinoid  in-\n",
      "secticides  and  proposed  \n",
      " Relevant score: 0.7205623461711794\n",
      "The  quality  of  pollinator  habitats  and  the  complementarity  and \n",
      "connectivity among individua\n",
      " Relevant score: 0.6836792815552349\n",
      "The  Federal  Emergency  Management  Agency  (FEMA)  published \n",
      "guidelines  on  nature-based  soluti\n",
      " Relevant score: 0.6797487724144816\n"
     ]
    }
   ],
   "source": [
    "query = \"the latest development in pollinators\"\n",
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_id,\n",
    "    query=query\n",
    ")\n",
    "\n",
    "for result in search_results.data[:5]:\n",
    "    print(result.content[0].text[:100] + '\\n Relevant score: ' + str(result.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c43361-5d0a-4aaf-9476-edada3f1e521",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äî Combine File Search with Web Search\n",
    "1. Enable both **file_search** and **web_search** in the Responses API.  \n",
    "2. Use a prompt that asks the model to merge insights from both sources.  \n",
    "   > Example: ‚ÄúUsing my uploaded notes and the latest web information, summarize the current trends on this topic.‚Äù  \n",
    "3. Review how the answer from your file and **current info** from the web.\n",
    "\n",
    "‚úÖ You‚Äôve created a RAG system that combines **private** and **public** data for comprehensive, up-to-date analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1b9195a-b8b0-453e-b1fd-933fc5f154fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The latest developments in pollinators focus on addressing the decline through integrated emergency management and alternative pollination strategies. Here are some key trends:\n",
       "\n",
       "1. **Integrated Emergency Management**: This approach emphasizes collaboration among international organizations, developed, and developing nations to address pollinator decline. It involves coordinated efforts to manage ecological, social, and policy aspects, aiming to create a comprehensive strategy for pollinator health.\n",
       "\n",
       "2. **Pollinator-Friendly Practices**: These include planting native flora, creating habitats, reducing outdoor lighting, and minimizing lawnmower use. Such practices aim to enhance pollinator habitats and support their populations.\n",
       "\n",
       "3. **Alternative Pollinators**: With the decline of honeybee populations, there is a push to explore and utilize alternative pollinators. This includes increasing the number of managed pollinators and ensuring they do not pose additional risks.\n",
       "\n",
       "4. **Global Stewardship and Collaboration**: Efforts are being made to align pollinator protection with global sustainability goals, such as the UN's Sustainable Development Goals. This involves fostering partnerships and information sharing among various stakeholders.\n",
       "\n",
       "5. **Emergency Training and Exercises**: Initiatives like Australia's \"Exercise Bee Prepared\" are being implemented to train stakeholders in managing pollinator emergencies and identifying invasive species.\n",
       "\n",
       "These strategies reflect a growing recognition of the critical role pollinators play in ecosystems and food security, and the need for comprehensive, coordinated efforts to mitigate their decline."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_search_response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input= query,\n",
    "    temperature = 0,\n",
    "    instructions=\"Using my uploaded notes and the latest web information, summarize the current trends on this topic\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_id],\n",
    "    },\n",
    "        {\n",
    "            \"type\": \"web_search\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "display(Markdown(combined_search_response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a317a-1743-4ad1-b8aa-98ebb3283fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
